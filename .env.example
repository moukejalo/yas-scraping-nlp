# ============================================================================
# Configuration LinkedIn Scraper - Opérateur Yas
# ============================================================================
# 
# INSTRUCTIONS:
# 1. Copiez ce fichier et renommez-le en ".env"
# 2. Remplissez vos informations
# 3. NE PARTAGEZ JAMAIS ce fichier (il contient vos identifiants)
# 4. Ajoutez ".env" à votre .gitignore
#
# ============================================================================

# ----------------------------------------------------------------------------
# IDENTIFIANTS LINKEDIN (REQUIS)
# ----------------------------------------------------------------------------

# Votre email LinkedIn
LINKEDIN_EMAIL=votre.email@example.com

# Votre mot de passe LinkedIn
# ⚠️ IMPORTANT: Gardez ce fichier secret !
LINKEDIN_PASSWORD=VotreMotDePasseSecurise123

# ----------------------------------------------------------------------------
# CONFIGURATION DE L'ENTREPRISE
# ----------------------------------------------------------------------------

# Nom de l'entreprise à analyser
COMPANY_NAME=Yas Guinée

# URL directe de la page entreprise (optionnel)
# Si fournie, le scraper ira directement à cette page
COMPANY_URL=

# ----------------------------------------------------------------------------
# PARAMÈTRES D'EXTRACTION
# ----------------------------------------------------------------------------

# Nombre maximum de posts à extraire
# Recommandé: 10-30 pour usage quotidien, 50-100 pour analyse complète
MAX_POSTS=30

# Nombre de scrolls pour charger les posts
# Formule approximative: num_scrolls = max_posts / 5
NUM_SCROLLS=6

# ----------------------------------------------------------------------------
# DÉLAIS ET TIMING (en secondes)
# ----------------------------------------------------------------------------

# Délai minimum entre les actions (en secondes)
# Augmentez pour être plus discret
MIN_DELAY=2.0

# Délai maximum entre les actions (en secondes)
MAX_DELAY=5.0

# Délai après chaque scroll
SCROLL_DELAY=3.0

# ----------------------------------------------------------------------------
# OPTIONS DU NAVIGATEUR
# ----------------------------------------------------------------------------

# Exécuter en mode sans interface graphique
# true = sans interface (plus rapide, pour serveur)
# false = avec interface (pour développement, débogage)
HEADLESS=false

# Taille de la fenêtre du navigateur
WINDOW_SIZE=1920,1080

# Désactiver le chargement des images (accélère l'extraction)
DISABLE_IMAGES=false

# ----------------------------------------------------------------------------
# TIMEOUTS (en secondes)
# ----------------------------------------------------------------------------

# Timeout pour le chargement d'une page
PAGE_LOAD_TIMEOUT=30

# Timeout pour attendre un élément
ELEMENT_WAIT_TIMEOUT=20

# ----------------------------------------------------------------------------
# CONFIGURATION PROXY (Optionnel)
# ----------------------------------------------------------------------------

# Utiliser un proxy
USE_PROXY=false

# Adresse du proxy
PROXY_HOST=

# Port du proxy
PROXY_PORT=

# Authentification proxy (optionnel)
PROXY_USERNAME=
PROXY_PASSWORD=

# ----------------------------------------------------------------------------
# LOGGING ET DEBUGGING
# ----------------------------------------------------------------------------

# Niveau de log
# Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Sauvegarder des captures d'écran
SAVE_SCREENSHOTS=true

# Dossier pour les captures d'écran
SCREENSHOT_DIR=screenshots

# ----------------------------------------------------------------------------
# SAUVEGARDE DES DONNÉES
# ----------------------------------------------------------------------------

# Dossier de sortie pour les fichiers CSV
OUTPUT_DIR=data

# Format de sortie
# Options: csv, json, excel
OUTPUT_FORMAT=csv

# ----------------------------------------------------------------------------
# CONFIGURATION AVANCÉE
# ----------------------------------------------------------------------------

# Préfixe pour les noms de fichiers générés
FILE_PREFIX=linkedin_yas

# Inclure timestamp dans le nom de fichier
INCLUDE_TIMESTAMP=true

# Sauvegarder aussi en JSON (en plus du CSV)
SAVE_JSON_BACKUP=false

# ----------------------------------------------------------------------------
# NOTIFICATIONS (Optionnel)
# ----------------------------------------------------------------------------

# Envoyer un email à la fin de l'extraction
SEND_EMAIL_NOTIFICATION=false

# Email destinataire
NOTIFICATION_EMAIL=

# Configuration SMTP
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=
SMTP_PASSWORD=

# ----------------------------------------------------------------------------
# PLANIFICATION (Pour automatisation)
# ----------------------------------------------------------------------------

# Heure d'exécution automatique (format 24h: HH:MM)
SCHEDULED_TIME=09:00

# Jours d'exécution (lundi=1, dimanche=7)
# Exemple: 1,2,3,4,5 pour du lundi au vendredi
SCHEDULED_DAYS=1,2,3,4,5

# ----------------------------------------------------------------------------
# SÉCURITÉ
# ----------------------------------------------------------------------------

# Activer le mode "stealth" (plus lent mais plus discret)
STEALTH_MODE=false

# Rotation User-Agent (changer à chaque exécution)
ROTATE_USER_AGENT=false

# ----------------------------------------------------------------------------
# ANALYSE DE SENTIMENTS
# ----------------------------------------------------------------------------

# Langue pour l'analyse de sentiments
# Options: fr, en, es, etc.
SENTIMENT_LANGUAGE=fr

# Seuil de polarité pour classifier comme positif
POSITIVE_THRESHOLD=0.1

# Seuil de polarité pour classifier comme négatif
NEGATIVE_THRESHOLD=-0.1

# ----------------------------------------------------------------------------
# CLASSIFICATION PAR SUJET
# ----------------------------------------------------------------------------

# Activer la classification automatique par sujet
ENABLE_TOPIC_CLASSIFICATION=true

# Fichier de configuration des mots-clés personnalisés (optionnel)
CUSTOM_KEYWORDS_FILE=

# ----------------------------------------------------------------------------
# INTÉGRATION STREAMLIT
# ----------------------------------------------------------------------------

# URL de l'application Streamlit (pour les notifications)
STREAMLIT_URL=http://localhost:8501

# Importer automatiquement dans Streamlit après extraction
AUTO_IMPORT_TO_STREAMLIT=false

# ----------------------------------------------------------------------------
# DÉVELOPPEMENT ET DEBUG
# ----------------------------------------------------------------------------

# Mode développement (plus de logs, pas de limits)
DEV_MODE=false

# Sauvegarder le HTML des pages pour debug
SAVE_PAGE_HTML=false

# Dossier pour les fichiers de debug
DEBUG_DIR=debug

# ----------------------------------------------------------------------------
# NOTES IMPORTANTES
# ----------------------------------------------------------------------------
#
# 1. SÉCURITÉ:
#    - Ne commitez JAMAIS ce fichier dans Git
#    - Utilisez des mots de passe forts
#    - Changez régulièrement vos mots de passe
#
# 2. LÉGALITÉ:
#    - Le scraping de LinkedIn peut violer leurs CGU
#    - Utilisez à des fins éducatives uniquement
#    - Préférez l'API officielle LinkedIn
#
# 3. PERFORMANCE:
#    - Ne dépassez pas 100 posts par extraction
#    - Limitez à 2-3 extractions par jour maximum
#    - Augmentez les délais si vous rencontrez des erreurs
#
# 4. SUPPORT:
#    - Documentation: docs/Guide_Utilisation_Selenium.md
#    - Issues: GitHub repository
#    - Email: support@votre-entreprise.com
#
# ============================================================================