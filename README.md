# ğŸ¤– LinkedIn Scraper avec Selenium - Analyse de Sentiments Yas

## ğŸ“‹ Vue d'ensemble

Solution complÃ¨te pour extraire et analyser les sentiments des posts LinkedIn de l'opÃ©rateur Yas. Cette solution utilise Selenium pour automatiser la collecte de donnÃ©es et fournit une analyse dÃ©taillÃ©e des sentiments clients.

### âš ï¸ Avertissement LÃ©gal

**Le scraping de LinkedIn viole leurs conditions d'utilisation.**  
Utilisez cette solution uniquement:
- Ã€ des fins Ã©ducatives
- Dans un environnement de test
- Avec l'autorisation explicite de LinkedIn

**Nous recommandons fortement l'utilisation de l'API officielle LinkedIn pour un usage en production.**

---

## ğŸ¯ FonctionnalitÃ©s

### âœ¨ Extraction AutomatisÃ©e
- âœ… Connexion automatique Ã  LinkedIn
- âœ… Navigation vers la page entreprise
- âœ… Scrolling intelligent pour charger les posts
- âœ… Extraction du texte complet des posts
- âœ… RÃ©cupÃ©ration des statistiques (likes, commentaires)
- âœ… Extraction des dates de publication

### ğŸ§  Analyse Intelligente
- ğŸ“Š Analyse de sentiments (positif/nÃ©gatif/neutre)
- ğŸ¯ Classification automatique par sujet
- ğŸ“ˆ Calcul de scores de sentiment
- ğŸ’¾ Export en CSV compatible Streamlit

### ğŸ›¡ï¸ SÃ©curitÃ© et DiscrÃ©tion
- ğŸ­ User-Agent personnalisÃ©
- â±ï¸ DÃ©lais alÃ©atoires (simulation humaine)
- ğŸ”’ Support proxy
- ğŸ“¸ Capture d'Ã©cran pour dÃ©bogage
- ğŸš« DÃ©sactivation des indicateurs d'automatisation

---

## ğŸ“¦ Structure du Projet

```
yas-linkedin-scraper/
â”‚
â”œâ”€â”€ linkedin_scraper_selenium.py  # Script principal
â”œâ”€â”€ config.py                     # Configuration avancÃ©e
â”œâ”€â”€ launcher.py                   # Interface de lancement
â”œâ”€â”€ app.py                        # Application Streamlit
â”‚
â”œâ”€â”€ requirements_selenium.txt     # DÃ©pendances Python
â”œâ”€â”€ .env.example                  # Template variables d'environnement
â”œâ”€â”€ .gitignore                    # Fichiers Ã  ignorer
â”‚
â”œâ”€â”€ data/                         # DonnÃ©es extraites (CSV)
â”œâ”€â”€ screenshots/                  # Captures d'Ã©cran
â”œâ”€â”€ logs/                         # Fichiers de log
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ Guide_Utilisation_Selenium.md
    â””â”€â”€ API_Alternative.md
```

---

## ğŸš€ Installation Rapide

### PrÃ©requis

- Python 3.8+
- Google Chrome
- Compte LinkedIn actif

### Installation en 3 Ã©tapes

```bash
# 1. Cloner ou crÃ©er le dossier projet
mkdir yas-linkedin-scraper
cd yas-linkedin-scraper

# 2. Installer les dÃ©pendances
pip install -r requirements_selenium.txt

# 3. TÃ©lÃ©charger les donnÃ©es TextBlob
python -m textblob.download_corpora
```

### VÃ©rification de l'installation

```bash
python launcher.py
```

Si tout est correctement installÃ©, vous verrez le menu principal.

---

## ğŸ’» Utilisation

### MÃ©thode 1: Interface Interactive (RecommandÃ©)

```bash
python launcher.py
```

**Menu disponible:**
1. Configuration manuelle
2. Quick Test (5 posts)
3. Monitoring quotidien (15 posts)
4. Rapport hebdomadaire (30 posts)
5. Analyse complÃ¨te (50-100 posts)

### MÃ©thode 2: Script Direct

```bash
python linkedin_scraper_selenium.py
```

Le script vous demandera:
- Email LinkedIn
- Mot de passe
- Nom de l'entreprise
- Nombre de posts Ã  extraire

### MÃ©thode 3: Configuration Programmatique

```python
from linkedin_scraper_selenium import LinkedInScraper
from config import ScraperConfig, ConfigPresets

# Utiliser une configuration prÃ©dÃ©finie
config = ConfigPresets.weekly_report()
config.email = "votre.email@example.com"
config.password = "votre_mot_de_passe"

# Ou crÃ©er une configuration personnalisÃ©e
config = ScraperConfig(
    email="votre.email@example.com",
    password="votre_mot_de_passe",
    company_name="Yas GuinÃ©e",
    max_posts=30,
    headless=True
)

# Lancer le scraper
scraper = LinkedInScraper(config.email, config.password, config.headless)
scraper.login()
scraper.navigate_to_company_page(config.company_name)
scraper.scroll_to_load_posts(num_scrolls=6)
posts = scraper.extract_posts(max_posts=config.max_posts)
scraper.save_to_csv(posts)
scraper.close()
```

---

## âš™ï¸ Configuration

### Variables d'Environnement

CrÃ©ez un fichier `.env`:

```env
# Identifiants LinkedIn
LINKEDIN_EMAIL=votre.email@example.com
LINKEDIN_PASSWORD=VotreMotDePasse123

# Configuration
COMPANY_NAME=Yas GuinÃ©e
MAX_POSTS=30
HEADLESS=False

# Proxy (optionnel)
USE_PROXY=False
PROXY_HOST=
PROXY_PORT=
```

### Configurations PrÃ©dÃ©finies

```python
from config import ConfigPresets

# Test rapide (5 posts, 1 minute)
config = ConfigPresets.quick_test()

# Monitoring quotidien (15 posts, 3 minutes)
config = ConfigPresets.daily_monitoring()

# Rapport hebdomadaire (30 posts, 5-7 minutes)
config = ConfigPresets.weekly_report()

# Analyse complÃ¨te (100 posts, 15-20 minutes)
config = ConfigPresets.full_analysis()

# Mode furtif (dÃ©lais longs)
config = ConfigPresets.stealth_mode()
```

---

## ğŸ“Š Format des DonnÃ©es Extraites

### Fichier CSV GÃ©nÃ©rÃ©

```csv
date,topic,comment,sentiment,score,reactions,comments,engagement
2024-11-10,RÃ©seau,"Excellent rÃ©seau 5G!",positif,0.85,245,12,257
2024-11-09,Prix,"Tarifs trop Ã©levÃ©s",nÃ©gatif,-0.65,89,34,123
2024-11-08,Service Client,"Ã‰quipe rÃ©active",positif,0.72,156,8,164
```

### Colonnes

| Colonne | Description | Type |
|---------|-------------|------|
| `date` | Date de publication | YYYY-MM-DD |
| `topic` | Sujet classifiÃ© | String |
| `comment` | Texte du post | String |
| `sentiment` | Sentiment dÃ©tectÃ© | positif/nÃ©gatif/neutre |
| `score` | Score de polaritÃ© | Float (-1 Ã  1) |
| `reactions` | Nombre de likes | Integer |
| `comments` | Nombre de commentaires | Integer |
| `engagement` | Total interactions | Integer |

---

## ğŸ¯ Classification des Sujets

### Sujets DÃ©tectÃ©s Automatiquement

| Sujet | Mots-ClÃ©s |
|-------|-----------|
| **RÃ©seau** | rÃ©seau, 4G, 5G, connexion, signal, antenne |
| **Service Client** | service, client, support, aide, assistance |
| **Prix** | prix, tarif, coÃ»t, facture, promotion |
| **Internet** | internet, data, dÃ©bit, vitesse, navigation |
| **Couverture** | couverture, zone, rural, urbain, rÃ©gion |
| **Application** | app, application, mobile, interface |
| **Offres** | forfait, package, abonnement, plan |

### Personnalisation

Modifiez `config.py` pour ajouter vos propres sujets:

```python
from config import KeywordConfig

keywords = KeywordConfig()
keywords.add_topic('5G', ['5g', 'cinquiÃ¨me gÃ©nÃ©ration', '5Ã¨me'])
keywords.add_keywords('Service Client', ['rÃ©pondeur', 'attente'])
```

---

## ğŸ“ˆ IntÃ©gration avec Streamlit

### Ã‰tape 1: Extraire les donnÃ©es

```bash
python linkedin_scraper_selenium.py
# Fichier gÃ©nÃ©rÃ©: linkedin_yas_posts_20241110_143022.csv
```

### Ã‰tape 2: Lancer Streamlit

```bash
streamlit run app.py
```

### Ã‰tape 3: Importer les donnÃ©es

1. Dans la sidebar, sÃ©lectionner "Importer un fichier CSV"
2. Choisir le fichier CSV gÃ©nÃ©rÃ©
3. Visualiser l'analyse complÃ¨te

### RÃ©sultats dans Streamlit

- ğŸ“Š Distribution des sentiments (graphique camembert)
- ğŸ“ˆ Ã‰volution temporelle
- ğŸ¯ Analyse par sujet
- ğŸ’¡ Recommandations automatiques
- ğŸ“¥ Export rapport PDF/CSV

---

## ğŸ› ï¸ RÃ©solution de ProblÃ¨mes

### ProblÃ¨me: "ChromeDriver not found"

**Solution:**
```bash
pip install --upgrade webdriver-manager
```

### ProblÃ¨me: "Login failed"

**Causes:**
- Identifiants incorrects
- 2FA activÃ© sur le compte
- LinkedIn a dÃ©tectÃ© une activitÃ© suspecte

**Solutions:**
1. VÃ©rifier email/mot de passe
2. DÃ©sactiver temporairement 2FA
3. Se connecter manuellement d'abord
4. Utiliser mode non-headless pour voir l'erreur

### ProblÃ¨me: "No posts found"

**Solutions:**
1. VÃ©rifier le nom exact de l'entreprise
2. Augmenter `num_scrolls` dans la config
3. VÃ©rifier manuellement que la page existe
4. Attendre quelques heures (rate limiting)

### ProblÃ¨me: "TimeoutException"

**Solution:**
```python
config.element_wait_timeout = 30  # Augmenter Ã  30s
config.page_load_timeout = 60     # Augmenter Ã  60s
```

### ProblÃ¨me: Compte Restreint

**Si LinkedIn dÃ©tecte le scraping:**
- â¸ï¸ ArrÃªter immÃ©diatement
- â³ Attendre 24-48h
- ğŸ“§ Contacter support LinkedIn si nÃ©cessaire
- âœ… Passer Ã  l'API officielle

---

## ğŸ“Š Performances et Limites

### Vitesse d'Extraction

| Configuration | Posts | DurÃ©e | Posts/min |
|---------------|-------|-------|-----------|
| Quick Test | 5 | 1 min | 5 |
| Daily | 15 | 3-4 min | 4 |
| Weekly | 30 | 6-8 min | 4 |
| Full | 100 | 20-30 min | 3-5 |

### Limites RecommandÃ©es

- â±ï¸ **FrÃ©quence**: Maximum 1 extraction/heure
- ğŸ“Š **Volume**: Maximum 100 posts/extraction
- ğŸ“… **Quotidien**: Maximum 3 extractions/jour
- ğŸš« **Ne pas**: Lancer 24/7

### Optimisations

```python
# AccÃ©lÃ©rer l'extraction
config.disable_images = True       # Ne pas charger les images
config.headless = True             # Mode sans interface
config.min_delay = 1.0            # RÃ©duire les dÃ©lais (risquÃ©)
```

---

## ğŸ”’ SÃ©curitÃ©

### Bonnes Pratiques

#### 1. Protection des Identifiants

âŒ **Ã€ NE PAS FAIRE:**
```python
email = "mon.email@gmail.com"  # CodÃ© en dur
```

âœ… **Ã€ FAIRE:**
```python
from dotenv import load_dotenv
import os

load_dotenv()
email = os.getenv('LINKEDIN_EMAIL')
```

#### 2. Fichier .gitignore

```
.env
*.csv
data/
screenshots/
logs/
venv/
__pycache__/
```

#### 3. Utilisation de Proxy

```python
config = ScraperConfig()
config.use_proxy = True
config.proxy_host = "proxy.example.com"
config.proxy_port = 8080
```

---

## ğŸ†˜ Support

### Documentation

- ğŸ“š Guide complet: `docs/Guide_Utilisation_Selenium.md`
- ğŸ”Œ API Alternative: `docs/API_Alternative.md`
- âš™ï¸ Configuration: `config.py`

### CommunautÃ©s

- **Stack Overflow**: Tag `selenium` + `linkedin`
- **Reddit**: r/selenium, r/webscraping
- **GitHub**: Issues du projet

### Contact

Pour toute question:
1. Consultez d'abord la documentation
2. VÃ©rifiez les issues GitHub
3. Contactez votre administrateur systÃ¨me

---

## âš–ï¸ Alternatives LÃ©gales

### 1. API Officielle LinkedIn (RECOMMANDÃ‰)

**Avantages:**
- âœ… 100% lÃ©gal
- âœ… Stable et fiable
- âœ… Support officiel
- âœ… Pas de risque de ban

**Ressources:**
- https://www.linkedin.com/developers/
- https://docs.microsoft.com/en-us/linkedin/

### 2. Export Manuel

**Processus:**
1. LinkedIn Analytics
2. Exporter en CSV
3. Importer dans Streamlit

### 3. Services Tiers AutorisÃ©s

- **Zapier**: Automatisation lÃ©gale
- **Phantombuster**: Service de scraping autorisÃ©
- **Apify**: Plateforme d'extraction

---

## ğŸ“ Changelog

### Version 1.0.0 (2024-11-10)

**FonctionnalitÃ©s initiales:**
- Extraction automatisÃ©e des posts LinkedIn
- Analyse de sentiments avec TextBlob
- Classification par sujet
- Export CSV
- Interface de lancement
- Configuration avancÃ©e
- Documentation complÃ¨te

**Ã€ venir:**
- Support multi-entreprises
- Analyse des commentaires
- Dashboard temps rÃ©el
- API REST
- Notifications par email

---

## ğŸ“„ Licence

Ce projet est fourni Ã  des fins **Ã‰DUCATIVES UNIQUEMENT**.

âš ï¸ **Disclaimer:**
- L'utilisation de ce code pour violer les CGU de LinkedIn est de votre responsabilitÃ©
- Les auteurs ne sont pas responsables des consÃ©quences
- Utilisez Ã  vos propres risques

**Recommandation:** Utilisez l'API officielle LinkedIn pour un usage en production.

---

## ğŸ™ Remerciements

- **Selenium**: Framework d'automatisation
- **TextBlob**: Analyse de sentiments
- **LinkedIn**: Plateforme sociale professionnelle
- **Streamlit**: Framework de visualisation

---

## âœ… Checklist de DÃ©ploiement

- [ ] Python 3.8+ installÃ©
- [ ] Chrome installÃ©
- [ ] DÃ©pendances installÃ©es (`pip install -r requirements_selenium.txt`)
- [ ] TextBlob corpus tÃ©lÃ©chargÃ©
- [ ] Fichier `.env` configurÃ©
- [ ] Identifiants LinkedIn testÃ©s
- [ ] Premier test rÃ©ussi (Quick Test)
- [ ] Documentation lue
- [ ] Streamlit fonctionnel

---

**ğŸ‰ Vous Ãªtes prÃªt Ã  utiliser le scraper LinkedIn avec Selenium !**

Pour dÃ©marrer: `python launcher.py`